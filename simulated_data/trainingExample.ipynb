{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Please delete this block if you don't use Google Colab. Please cd to the script folder. \n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('drive/My Drive/YourFolderName') #Need to change the address to where your script is\n",
        "os.listdir('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocj4EuyfOtGd",
        "outputId": "9489b67e-e4a0-4b35-a2ba-9bdc2e57f29a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['output',\n",
              " 'train.npy',\n",
              " 'valid.npy',\n",
              " 'label.npy',\n",
              " 'test.npy',\n",
              " 'train_100.npy',\n",
              " 'train_50.npy',\n",
              " 'valid_A45.npy',\n",
              " 'label_A45.npy',\n",
              " 'test_A45.npy',\n",
              " 'train_A45.npy',\n",
              " 'orientation_test.npy',\n",
              " 'train_A45.ipynb',\n",
              " 'train_20.npy',\n",
              " 'train_10.npy',\n",
              " 'log.csv',\n",
              " 'model.hdf5',\n",
              " 'train_5.npy',\n",
              " 'train.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import gc\n",
        "import csv\n",
        "from skimage import io\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger\n",
        "from tensorflow.keras import backend as keras\n",
        "from tensorflow.keras.initializers import *\n",
        "from tensorflow.data import Dataset"
      ],
      "metadata": {
        "id": "nfXxQYjTdtZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htkf_zzYQKYy",
        "outputId": "ca2d3075-2245-4508-b724-342ab8144619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(589, 61, 256)\n",
            "(5371, 61, 256)\n",
            "(5371, 61, 256)\n"
          ]
        }
      ],
      "source": [
        "#Load training data and validation data\n",
        "train = (np.load('train.npy',allow_pickle=True).astype('float32'))*255\n",
        "label = (np.load('label.npy',allow_pickle=True).astype('float32'))*255\n",
        "valid = (np.load('valid.npy',allow_pickle=True).astype('float32'))*255\n",
        "trainSize = train.shape[0]\n",
        "validSize = valid.shape[0]\n",
        "labelSize = label.shape[0]\n",
        "print(trainSize)\n",
        "print(validSize) \n",
        "print(labelSize) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the training dataset\n",
        "fig, ax = plt.subplots()\n",
        "h = ax.imshow(train[5,:,:])\n",
        "fig.colorbar(h)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "h = ax.imshow(valid[5,:,:])\n",
        "fig.colorbar(h)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "h = ax.imshow(label[5,:,:])\n",
        "fig.colorbar(h)"
      ],
      "metadata": {
        "id": "ItbPPDV9LnQ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "4d4c6011-b1ce-4ef9-cc3c-3c8ec860574c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fb41936ab50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exYcPI9bsxM0",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Function and model defining\n",
        "def masker(imgs):# The random masking function\n",
        "\tmask = np.ones((imgs.shape[0],61,256)).astype('float32')\n",
        "\tfor i in range(mask.shape[0]):\n",
        "\t\ttemp = np.ones((61,256)).astype('float32')\n",
        "\t\tst = np.random.randint(0,42)\n",
        "\t\ttemp[st:st+20,:] = 0\n",
        "\t\tmask[i,:,:] = temp\n",
        "\timgs2 = imgs*mask\n",
        "\treturn (imgs2,mask)\n",
        " \n",
        "def get_unet():# Define the U-Net with MSE loss\n",
        "\t\tinputs = Input((61,256,1))\n",
        "\t\tpadd1 = ZeroPadding2D(padding=((0,3), (0,0)))(inputs)\n",
        "\t\tconv1 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(padd1)\n",
        "\t\tprint (\"conv1 shape:\",conv1.shape)\n",
        "\t\tconv1 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "\t\tprint (\"conv1 shape:\",conv1.shape)\n",
        "\t\tpool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\t\tprint (\"pool1 shape:\",pool1.shape)\n",
        "\n",
        "\t\tconv2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "\t\tprint (\"conv2 shape:\",conv2.shape)\n",
        "\t\tconv2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "\t\tprint (\"conv2 shape:\",conv2.shape)\n",
        "\t\tpool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\t\tprint (\"pool2 shape:\",pool2.shape)\n",
        "\n",
        "\t\tconv3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "\t\tprint (\"conv3 shape:\",conv3.shape)\n",
        "\t\tconv3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "\t\tprint (\"conv3 shape:\",conv3.shape)\n",
        "\t\tpool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\t\tprint (\"pool3 shape:\",pool3.shape)\n",
        "\n",
        "\t\tconv4 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "\t\tconv4 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "\t\tdrop4 = Dropout(0.5)(conv4)\n",
        "\n",
        "\t\tup7 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv4))\n",
        "\t\tmerge7 = concatenate([conv3,up7], axis = 3)\n",
        "\t\tconv7 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "\t\tconv7 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "\t\tup8 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "\t\tmerge8 = concatenate([conv2,up8], axis = 3)\n",
        "\t\tconv8 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "\t\tconv8 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "\t\tup9 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "\t\tmerge9 = concatenate([conv1,up9], axis = 3)\n",
        "\t\tconv9 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "\t\tconv9 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "\t\t\n",
        "\t\tconv10 = Conv2D(1, 1, activation = 'linear')(conv9)\n",
        "\t\tconv10 = Cropping2D(((0,3),(0,0)))(conv10)\n",
        "\t\tmodel = Model(inputs = inputs, outputs = conv10)\n",
        "\t\tmodel.compile(optimizer = Adam(learning_rate = 5e-6), loss = 'MSE', metrics = 'MSE') \n",
        "\t\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model training\n",
        "model = get_unet()\n",
        "model_checkpoint = ModelCheckpoint('model.hdf5', monitor='loss',verbose=1, save_best_only=False)\n",
        "f = open('log.csv', 'w+')\n",
        "f.close()\n",
        "model.summary()\n",
        "epochVolume = 1000 #parameter: how many sinogram images will be included in one epoch\n",
        "epoch = 200 #parameter: total epoch numbers before training stop\n",
        "sample_pred = np.random.choice(np.array(range(validSize)),10) # will select 10 random sinogram images in the validation data and output the prediction result every epoch\n",
        "sample_pred = valid[sample_pred] # will select 10 random sinogram images in the validation data and output the prediction result every epoch\n",
        "baseline_MSE = np.mean(np.square(valid - label))\n",
        "baseline_SSIM = tf.image.ssim(valid,label,max_val=255)\n",
        "baseline_PSNR = tf.image.psnr(valid,label,max_val=255)\n",
        "print('Baseline MSE: '+str(baseline_MSE) + '; Baseline SSIM: '+str(baseline_SSIM.numpy()) + '; BaselinePSNR: ' + str(baseline_PSNR.numpy()))\n",
        "for epochs in range(epoch):\n",
        "  print('Epoch: '+str(epochs)+' 1st predicting')\n",
        "  sample = np.random.choice(np.array(range(trainSize)),epochVolume) #Randomly sample image in the training dataset\n",
        "  sample = train[sample] #Randomly sample image in the training dataset\n",
        "  imgs_1st_predict = model.predict(sample, batch_size=1, verbose=1).squeeze() #Make 1st prediction from the sampled images\n",
        "  imgs_2nd_masked = masker(imgs_1st_predict)[0] #Mask the 1st predictions\n",
        "  print('Epoch: '+str(epochs)+' training')\n",
        "  h = model.fit(imgs_2nd_masked, imgs_1st_predict, batch_size=1, validation_data = (valid, label), epochs=1, verbose=1,  shuffle=True, callbacks=[model_checkpoint]) #Use the 1st predictions and their masked versions for training\n",
        "  print('Epoch: '+str(epochs)+' 2nd predicting')\n",
        "  imgs_1st_predict = model.predict(sample_pred, batch_size=2, verbose=1).squeeze() #Try to predict the 10 random sinogram images\n",
        "  imgs_2nd_predict = model.predict(masker(imgs_1st_predict)[0], batch_size=2, verbose=1).squeeze() #Try to predict the masked 10 random sinogram images\n",
        "  print('Epoch: '+str(epochs)+' saving montages')\n",
        "  opt1 = np.concatenate((np.concatenate((imgs_1st_predict[:5]),axis = 1) , np.concatenate((imgs_1st_predict[5:]),axis = 1)) , axis = 0)\n",
        "  opt2 = np.concatenate((np.concatenate((imgs_2nd_predict[:5]),axis = 1) , np.concatenate((imgs_2nd_predict[5:]),axis = 1)) , axis = 0)\n",
        "  opt1[opt1<0] = 0\n",
        "  opt1[opt1>255] = 255\n",
        "  opt2[opt2<0] = 0\n",
        "  opt2[opt2>255] = 255\n",
        "  opt1 = opt1.astype('uint8')\n",
        "  opt2 = opt2.astype('uint8')\n",
        "  cv2.imwrite('output/1st/'+str(epochs)+'.png', opt1 ) #Write the predictions of the 10 random sinogram images\n",
        "  cv2.imwrite('output/2nd/'+str(epochs)+'.png', opt2 ) #Write the predictions of the masked predictions of the 10 random sinogram images\n",
        "  _ = gc.collect()\n",
        "  tf.keras.backend.clear_session()\n",
        "  f = open('log.csv', 'a')\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow( [h.history['MSE'][0],h.history['val_MSE'][0],baseline_MSE] )\n",
        "  f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2lcLMxXMpWi",
        "outputId": "a1727aeb-8763-4874-e268-3923437bd71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1 shape: (None, 64, 256, 128)\n",
            "conv1 shape: (None, 64, 256, 128)\n",
            "pool1 shape: (None, 32, 128, 128)\n",
            "conv2 shape: (None, 32, 128, 256)\n",
            "conv2 shape: (None, 32, 128, 256)\n",
            "pool2 shape: (None, 16, 64, 256)\n",
            "conv3 shape: (None, 16, 64, 512)\n",
            "conv3 shape: (None, 16, 64, 512)\n",
            "pool3 shape: (None, 8, 32, 512)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 61, 256, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 64, 256, 1)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 64, 256, 128  1280        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 64, 256, 128  147584      ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 32, 128, 128  0           ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 128, 256  295168      ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 128, 256  590080      ['conv2d_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 64, 256)  0          ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 64, 512)  1180160     ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 64, 512)  2359808     ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 8, 32, 512)  0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 8, 32, 1024)  4719616     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 8, 32, 1024)  9438208     ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 16, 64, 1024  0           ['conv2d_7[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 64, 512)  2097664     ['up_sampling2d[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 64, 1024  0           ['conv2d_5[0][0]',               \n",
            "                                )                                 'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 64, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 64, 512)  2359808     ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 32, 128, 512  0          ['conv2d_10[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 128, 256  524544      ['up_sampling2d_1[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 32, 128, 512  0           ['conv2d_3[0][0]',               \n",
            "                                )                                 'conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 128, 256  1179904     ['concatenate_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 128, 256  590080      ['conv2d_12[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 64, 256, 256  0          ['conv2d_13[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 64, 256, 128  131200      ['up_sampling2d_2[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 64, 256, 256  0           ['conv2d_1[0][0]',               \n",
            "                                )                                 'conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 64, 256, 128  295040      ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 64, 256, 128  147584      ['conv2d_15[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 64, 256, 1)   129         ['conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " cropping2d (Cropping2D)        (None, 61, 256, 1)   0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 30,776,961\n",
            "Trainable params: 30,776,961\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Baseline MSE: 647.49744; Baseline SSIM: 0.8497627; BaselinePSNR: 20.018425\n",
            "Epoch: 0 1st predicting\n",
            "1000/1000 [==============================] - 12s 4ms/step\n",
            "Epoch: 0 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 136.0616 - MSE: 136.0617\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 52s 45ms/step - loss: 136.0616 - MSE: 136.0617 - val_loss: 4742.1396 - val_MSE: 4742.1445\n",
            "Epoch: 0 2nd predicting\n",
            "5/5 [==============================] - 1s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 0 saving montages\n",
            "Epoch: 1 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 1 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 89.7143 - MSE: 89.7142\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 89.7143 - MSE: 89.7142 - val_loss: 5863.4297 - val_MSE: 5863.4375\n",
            "Epoch: 1 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 1 saving montages\n",
            "Epoch: 2 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 2 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 205.2515 - MSE: 205.2515\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 205.3606 - MSE: 205.3606 - val_loss: 5677.1172 - val_MSE: 5677.1245\n",
            "Epoch: 2 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 2 saving montages\n",
            "Epoch: 3 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 3 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 108.0080 - MSE: 108.0079\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 107.9381 - MSE: 107.9381 - val_loss: 5018.2935 - val_MSE: 5018.2939\n",
            "Epoch: 3 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 3 saving montages\n",
            "Epoch: 4 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 4 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 76.2677 - MSE: 76.2677\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 76.2677 - MSE: 76.2677 - val_loss: 5163.4453 - val_MSE: 5163.4463\n",
            "Epoch: 4 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 4 saving montages\n",
            "Epoch: 5 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 5 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 60.2314 - MSE: 60.2314\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 60.2314 - MSE: 60.2314 - val_loss: 5846.4170 - val_MSE: 5846.4072\n",
            "Epoch: 5 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 5 saving montages\n",
            "Epoch: 6 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 6 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 69.2482 - MSE: 69.2482\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 69.2585 - MSE: 69.2585 - val_loss: 6685.7822 - val_MSE: 6685.7773\n",
            "Epoch: 6 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 6 saving montages\n",
            "Epoch: 7 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 7 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 56.3794 - MSE: 56.3794\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 56.3717 - MSE: 56.3717 - val_loss: 6841.8149 - val_MSE: 6841.8105\n",
            "Epoch: 7 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 7 saving montages\n",
            "Epoch: 8 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 8 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 81.9911 - MSE: 81.9911\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 81.9519 - MSE: 81.9520 - val_loss: 7654.1724 - val_MSE: 7654.1704\n",
            "Epoch: 8 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 8 saving montages\n",
            "Epoch: 9 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 9 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 43.5797 - MSE: 43.5797\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 44ms/step - loss: 43.5215 - MSE: 43.5215 - val_loss: 7878.9043 - val_MSE: 7878.9150\n",
            "Epoch: 9 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 9 saving montages\n",
            "Epoch: 10 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 10 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 58.4352 - MSE: 58.4353\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 58.4264 - MSE: 58.4264 - val_loss: 6028.7988 - val_MSE: 6028.7974\n",
            "Epoch: 10 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 10 saving montages\n",
            "Epoch: 11 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 11 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 41.1087 - MSE: 41.1086\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 41.1087 - MSE: 41.1086 - val_loss: 6081.9517 - val_MSE: 6081.9546\n",
            "Epoch: 11 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 11 saving montages\n",
            "Epoch: 12 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 12 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 35.7188 - MSE: 35.7188\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 35.6979 - MSE: 35.6979 - val_loss: 5988.4980 - val_MSE: 5988.4980\n",
            "Epoch: 12 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 12 saving montages\n",
            "Epoch: 13 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 13 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 46.7061 - MSE: 46.7060\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 46.7061 - MSE: 46.7060 - val_loss: 6359.4346 - val_MSE: 6359.4316\n",
            "Epoch: 13 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 13 saving montages\n",
            "Epoch: 14 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 14 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 38.2435 - MSE: 38.2436\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 38.2435 - MSE: 38.2436 - val_loss: 6806.2754 - val_MSE: 6806.2896\n",
            "Epoch: 14 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 14 saving montages\n",
            "Epoch: 15 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 15 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 35.3865 - MSE: 35.3865\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 35.3865 - MSE: 35.3865 - val_loss: 6628.3916 - val_MSE: 6628.3960\n",
            "Epoch: 15 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 15 saving montages\n",
            "Epoch: 16 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 16 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 37.2588 - MSE: 37.2588\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 37.2259 - MSE: 37.2259 - val_loss: 6960.1221 - val_MSE: 6960.1050\n",
            "Epoch: 16 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 16 saving montages\n",
            "Epoch: 17 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 17 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 41.4010 - MSE: 41.4010\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 41.3510 - MSE: 41.3510 - val_loss: 6747.5264 - val_MSE: 6747.5146\n",
            "Epoch: 17 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 17 saving montages\n",
            "Epoch: 18 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 18 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 29.6352 - MSE: 29.6352\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 29.6762 - MSE: 29.6762 - val_loss: 6731.2305 - val_MSE: 6731.2285\n",
            "Epoch: 18 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 18 saving montages\n",
            "Epoch: 19 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 19 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 24.2708 - MSE: 24.2708\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 24.2708 - MSE: 24.2708 - val_loss: 7983.3403 - val_MSE: 7983.3452\n",
            "Epoch: 19 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 19 saving montages\n",
            "Epoch: 20 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 20 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 42.3578 - MSE: 42.3577\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 42.3345 - MSE: 42.3344 - val_loss: 7557.9268 - val_MSE: 7557.9404\n",
            "Epoch: 20 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 20 saving montages\n",
            "Epoch: 21 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 21 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 37.0889 - MSE: 37.0889\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 37.0762 - MSE: 37.0762 - val_loss: 6499.0386 - val_MSE: 6499.0435\n",
            "Epoch: 21 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 21 saving montages\n",
            "Epoch: 22 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 22 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 21.7587 - MSE: 21.7587\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 21.8695 - MSE: 21.8695 - val_loss: 5901.5786 - val_MSE: 5901.5732\n",
            "Epoch: 22 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 22 saving montages\n",
            "Epoch: 23 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 23 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 18.7983 - MSE: 18.7983\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 46s 45ms/step - loss: 18.8142 - MSE: 18.8142 - val_loss: 5877.2358 - val_MSE: 5877.2339\n",
            "Epoch: 23 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 23 saving montages\n",
            "Epoch: 24 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 24 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 17.2967 - MSE: 17.2967\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 17.2613 - MSE: 17.2613 - val_loss: 5407.7773 - val_MSE: 5407.7803\n",
            "Epoch: 24 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 24 saving montages\n",
            "Epoch: 25 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 25 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 24.2966 - MSE: 24.2966\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 39s 38ms/step - loss: 24.2966 - MSE: 24.2966 - val_loss: 5860.3633 - val_MSE: 5860.3750\n",
            "Epoch: 25 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 25 saving montages\n",
            "Epoch: 26 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 26 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 33.5051 - MSE: 33.5051\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 33.4439 - MSE: 33.4438 - val_loss: 4992.0776 - val_MSE: 4992.0767\n",
            "Epoch: 26 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 26 saving montages\n",
            "Epoch: 27 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 27 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 20.0696 - MSE: 20.0696\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 20.0696 - MSE: 20.0696 - val_loss: 5288.1465 - val_MSE: 5288.1499\n",
            "Epoch: 27 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 27 saving montages\n",
            "Epoch: 28 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 28 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 23.3566 - MSE: 23.3566\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 23.3566 - MSE: 23.3566 - val_loss: 5712.6528 - val_MSE: 5712.6528\n",
            "Epoch: 28 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 28 saving montages\n",
            "Epoch: 29 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 29 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 21.6322 - MSE: 21.6322\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 21.6541 - MSE: 21.6541 - val_loss: 5420.3618 - val_MSE: 5420.3604\n",
            "Epoch: 29 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 29 saving montages\n",
            "Epoch: 30 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 30 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 21.0461 - MSE: 21.0461\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 21.0442 - MSE: 21.0442 - val_loss: 5642.1431 - val_MSE: 5642.1357\n",
            "Epoch: 30 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 30 saving montages\n",
            "Epoch: 31 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 31 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 23.0693 - MSE: 23.0693\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 39ms/step - loss: 23.0237 - MSE: 23.0237 - val_loss: 6257.8374 - val_MSE: 6257.8301\n",
            "Epoch: 31 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 31 saving montages\n",
            "Epoch: 32 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 32 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 20.7794 - MSE: 20.7794\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 20.7401 - MSE: 20.7401 - val_loss: 4953.2056 - val_MSE: 4953.2036\n",
            "Epoch: 32 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 32 saving montages\n",
            "Epoch: 33 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 33 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 15.9993 - MSE: 15.9993\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 15.9854 - MSE: 15.9854 - val_loss: 5222.4307 - val_MSE: 5222.4399\n",
            "Epoch: 33 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 33 saving montages\n",
            "Epoch: 34 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 34 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 19.7220 - MSE: 19.7220\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 19.7290 - MSE: 19.7290 - val_loss: 5312.2300 - val_MSE: 5312.2275\n",
            "Epoch: 34 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 34 saving montages\n",
            "Epoch: 35 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 35 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 14.7505 - MSE: 14.7505\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 14.7352 - MSE: 14.7352 - val_loss: 6449.6323 - val_MSE: 6449.6426\n",
            "Epoch: 35 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 35 saving montages\n",
            "Epoch: 36 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 36 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 22.8906 - MSE: 22.8906\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 39ms/step - loss: 22.8592 - MSE: 22.8592 - val_loss: 6198.2397 - val_MSE: 6198.2388\n",
            "Epoch: 36 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 36 saving montages\n",
            "Epoch: 37 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 37 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 21.4503 - MSE: 21.4503\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 39ms/step - loss: 21.4363 - MSE: 21.4363 - val_loss: 5842.2988 - val_MSE: 5842.2900\n",
            "Epoch: 37 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 37 saving montages\n",
            "Epoch: 38 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 38 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 20.2989 - MSE: 20.2989\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 20.2989 - MSE: 20.2989 - val_loss: 6128.7100 - val_MSE: 6128.7207\n",
            "Epoch: 38 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 38 saving montages\n",
            "Epoch: 39 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 39 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 19.9540 - MSE: 19.9540\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 19.9540 - MSE: 19.9540 - val_loss: 5961.4766 - val_MSE: 5961.4780\n",
            "Epoch: 39 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 39 saving montages\n",
            "Epoch: 40 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 40 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 20.3419 - MSE: 20.3419\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 44ms/step - loss: 20.3074 - MSE: 20.3074 - val_loss: 6569.9521 - val_MSE: 6569.9614\n",
            "Epoch: 40 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 40 saving montages\n",
            "Epoch: 41 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 41 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 20.6571 - MSE: 20.6571\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 20.6668 - MSE: 20.6668 - val_loss: 7075.9492 - val_MSE: 7075.9512\n",
            "Epoch: 41 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 41 saving montages\n",
            "Epoch: 42 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 42 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 23.4751 - MSE: 23.4751\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 23.4574 - MSE: 23.4574 - val_loss: 6077.8525 - val_MSE: 6077.8560\n",
            "Epoch: 42 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 42 saving montages\n",
            "Epoch: 43 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 43 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 14.4987 - MSE: 14.4987\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 14.4925 - MSE: 14.4925 - val_loss: 5817.9507 - val_MSE: 5817.9512\n",
            "Epoch: 43 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 43 saving montages\n",
            "Epoch: 44 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 44 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 16.7856 - MSE: 16.7856\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 16.7731 - MSE: 16.7731 - val_loss: 5964.3042 - val_MSE: 5964.3062\n",
            "Epoch: 44 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 44 saving montages\n",
            "Epoch: 45 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 45 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 17.8625 - MSE: 17.8625\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 17.8517 - MSE: 17.8517 - val_loss: 6016.8862 - val_MSE: 6016.8804\n",
            "Epoch: 45 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 45 saving montages\n",
            "Epoch: 46 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 46 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 18.3122 - MSE: 18.3121\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 18.2633 - MSE: 18.2632 - val_loss: 5341.1489 - val_MSE: 5341.1606\n",
            "Epoch: 46 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 46 saving montages\n",
            "Epoch: 47 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 47 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 17.1345 - MSE: 17.1345\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 17.1580 - MSE: 17.1580 - val_loss: 5912.5708 - val_MSE: 5912.5820\n",
            "Epoch: 47 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 47 saving montages\n",
            "Epoch: 48 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 48 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 15.6875 - MSE: 15.6876\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 15.6875 - MSE: 15.6876 - val_loss: 5927.6792 - val_MSE: 5927.6655\n",
            "Epoch: 48 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 48 saving montages\n",
            "Epoch: 49 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 49 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 19.5756 - MSE: 19.5756\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 19.5756 - MSE: 19.5756 - val_loss: 5417.5054 - val_MSE: 5417.5068\n",
            "Epoch: 49 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 49 saving montages\n",
            "Epoch: 50 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 50 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 12.4537 - MSE: 12.4537\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 12.4433 - MSE: 12.4433 - val_loss: 5431.5039 - val_MSE: 5431.4985\n",
            "Epoch: 50 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 50 saving montages\n",
            "Epoch: 51 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 51 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 11.5411 - MSE: 11.5411\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 11.5728 - MSE: 11.5728 - val_loss: 5546.3662 - val_MSE: 5546.3706\n",
            "Epoch: 51 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 51 saving montages\n",
            "Epoch: 52 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 52 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 17.2306 - MSE: 17.2306\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 17.2306 - MSE: 17.2306 - val_loss: 5363.9766 - val_MSE: 5363.9683\n",
            "Epoch: 52 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 52 saving montages\n",
            "Epoch: 53 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 53 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 15.0170 - MSE: 15.0170\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 15.2161 - MSE: 15.2161 - val_loss: 5915.0308 - val_MSE: 5915.0205\n",
            "Epoch: 53 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 53 saving montages\n",
            "Epoch: 54 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 54 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 12.7437 - MSE: 12.7437\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 12.7437 - MSE: 12.7437 - val_loss: 5730.9106 - val_MSE: 5730.9111\n",
            "Epoch: 54 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 54 saving montages\n",
            "Epoch: 55 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 55 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 11.7259 - MSE: 11.7259\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 44ms/step - loss: 11.7259 - MSE: 11.7259 - val_loss: 5527.6631 - val_MSE: 5527.6611\n",
            "Epoch: 55 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 55 saving montages\n",
            "Epoch: 56 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 56 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 19.7769 - MSE: 19.7769\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 19.7656 - MSE: 19.7656 - val_loss: 5502.0645 - val_MSE: 5502.0679\n",
            "Epoch: 56 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 56 saving montages\n",
            "Epoch: 57 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 57 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 11.5051 - MSE: 11.5051\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 11.5051 - MSE: 11.5051 - val_loss: 5980.7310 - val_MSE: 5980.7329\n",
            "Epoch: 57 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 57 saving montages\n",
            "Epoch: 58 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 58 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 15.4094 - MSE: 15.4094\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 15.3755 - MSE: 15.3755 - val_loss: 5978.1987 - val_MSE: 5978.2188\n",
            "Epoch: 58 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 58 saving montages\n",
            "Epoch: 59 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 59 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 13.7722 - MSE: 13.7722\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 13.7722 - MSE: 13.7722 - val_loss: 5596.4150 - val_MSE: 5596.4082\n",
            "Epoch: 59 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 59 saving montages\n",
            "Epoch: 60 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 60 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 14.2095 - MSE: 14.2095\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 14.1862 - MSE: 14.1862 - val_loss: 5088.7178 - val_MSE: 5088.7183\n",
            "Epoch: 60 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 60 saving montages\n",
            "Epoch: 61 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 61 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 19.7861 - MSE: 19.7860\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 19.7861 - MSE: 19.7860 - val_loss: 4683.8076 - val_MSE: 4683.7969\n",
            "Epoch: 61 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 61 saving montages\n",
            "Epoch: 62 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 62 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 7.6191 - MSE: 7.6190\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 7.6117 - MSE: 7.6117 - val_loss: 4733.1836 - val_MSE: 4733.1768\n",
            "Epoch: 62 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 62 saving montages\n",
            "Epoch: 63 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 63 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 11.1894 - MSE: 11.1894\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 11.1791 - MSE: 11.1791 - val_loss: 4834.4297 - val_MSE: 4834.4072\n",
            "Epoch: 63 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 63 saving montages\n",
            "Epoch: 64 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 64 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 12.4453 - MSE: 12.4452\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 12.4313 - MSE: 12.4313 - val_loss: 5248.4297 - val_MSE: 5248.4209\n",
            "Epoch: 64 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 64 saving montages\n",
            "Epoch: 65 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 65 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 13.2332 - MSE: 13.2332\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 13.1991 - MSE: 13.1991 - val_loss: 5140.8696 - val_MSE: 5140.8740\n",
            "Epoch: 65 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 65 saving montages\n",
            "Epoch: 66 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 66 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 9.3197 - MSE: 9.3197\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 9.3143 - MSE: 9.3143 - val_loss: 5201.9902 - val_MSE: 5201.9956\n",
            "Epoch: 66 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 66 saving montages\n",
            "Epoch: 67 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 67 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 13.2459 - MSE: 13.2460\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 13.2268 - MSE: 13.2268 - val_loss: 4475.8394 - val_MSE: 4475.8413\n",
            "Epoch: 67 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 67 saving montages\n",
            "Epoch: 68 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 68 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 8.1659 - MSE: 8.1659\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 8.1687 - MSE: 8.1687 - val_loss: 4400.4224 - val_MSE: 4400.4126\n",
            "Epoch: 68 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 68 saving montages\n",
            "Epoch: 69 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 69 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 9.6415 - MSE: 9.6415\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 9.6336 - MSE: 9.6336 - val_loss: 4423.5259 - val_MSE: 4423.5264\n",
            "Epoch: 69 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 69 saving montages\n",
            "Epoch: 70 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 70 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 11.7904 - MSE: 11.7904\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 40ms/step - loss: 11.7904 - MSE: 11.7904 - val_loss: 4405.8125 - val_MSE: 4405.8013\n",
            "Epoch: 70 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 70 saving montages\n",
            "Epoch: 71 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 71 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 8.9767 - MSE: 8.9767\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 8.9767 - MSE: 8.9767 - val_loss: 4443.0493 - val_MSE: 4443.0400\n",
            "Epoch: 71 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 71 saving montages\n",
            "Epoch: 72 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 72 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 8.0459 - MSE: 8.0459\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 8.0459 - MSE: 8.0459 - val_loss: 4480.7773 - val_MSE: 4480.7866\n",
            "Epoch: 72 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 72 saving montages\n",
            "Epoch: 73 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 73 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 11.7066 - MSE: 11.7066\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 11.7113 - MSE: 11.7113 - val_loss: 4830.2671 - val_MSE: 4830.2651\n",
            "Epoch: 73 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 73 saving montages\n",
            "Epoch: 74 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 74 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 9.4012 - MSE: 9.4012\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 9.3908 - MSE: 9.3908 - val_loss: 4351.6846 - val_MSE: 4351.6797\n",
            "Epoch: 74 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 74 saving montages\n",
            "Epoch: 75 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 75 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 10.4302 - MSE: 10.4302\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 10.4302 - MSE: 10.4302 - val_loss: 5061.9834 - val_MSE: 5061.9790\n",
            "Epoch: 75 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 75 saving montages\n",
            "Epoch: 76 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 76 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 14.2364 - MSE: 14.2365\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 14.2364 - MSE: 14.2365 - val_loss: 4987.0469 - val_MSE: 4987.0542\n",
            "Epoch: 76 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 76 saving montages\n",
            "Epoch: 77 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 77 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 8.8264 - MSE: 8.8264\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 40ms/step - loss: 8.8219 - MSE: 8.8219 - val_loss: 4855.1162 - val_MSE: 4855.1309\n",
            "Epoch: 77 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 77 saving montages\n",
            "Epoch: 78 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 78 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 10.4391 - MSE: 10.4391\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 10.4121 - MSE: 10.4121 - val_loss: 4796.0039 - val_MSE: 4796.0059\n",
            "Epoch: 78 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 78 saving montages\n",
            "Epoch: 79 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 79 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 10.6376 - MSE: 10.6376\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 10.6188 - MSE: 10.6188 - val_loss: 4912.8296 - val_MSE: 4912.8286\n",
            "Epoch: 79 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 79 saving montages\n",
            "Epoch: 80 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 80 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 8.2362 - MSE: 8.2362\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 39ms/step - loss: 8.2305 - MSE: 8.2305 - val_loss: 4879.0957 - val_MSE: 4879.0928\n",
            "Epoch: 80 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 80 saving montages\n",
            "Epoch: 81 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 81 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 9.4024 - MSE: 9.4024\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 9.3974 - MSE: 9.3974 - val_loss: 5343.9067 - val_MSE: 5343.9053\n",
            "Epoch: 81 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 81 saving montages\n",
            "Epoch: 82 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 82 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 11.6470 - MSE: 11.6470\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 11.6200 - MSE: 11.6200 - val_loss: 4836.7534 - val_MSE: 4836.7593\n",
            "Epoch: 82 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 82 saving montages\n",
            "Epoch: 83 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 83 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 7.9235 - MSE: 7.9235\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 38s 37ms/step - loss: 7.9460 - MSE: 7.9460 - val_loss: 5429.9072 - val_MSE: 5429.9185\n",
            "Epoch: 83 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 83 saving montages\n",
            "Epoch: 84 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 84 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 8.1508 - MSE: 8.1508\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 8.1399 - MSE: 8.1399 - val_loss: 6523.3970 - val_MSE: 6523.4004\n",
            "Epoch: 84 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 84 saving montages\n",
            "Epoch: 85 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 85 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 14.3654 - MSE: 14.3654\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 14.3276 - MSE: 14.3276 - val_loss: 6623.6499 - val_MSE: 6623.6646\n",
            "Epoch: 85 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 85 saving montages\n",
            "Epoch: 86 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 86 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 9.7776 - MSE: 9.7776\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 9.7570 - MSE: 9.7570 - val_loss: 6398.5850 - val_MSE: 6398.5972\n",
            "Epoch: 86 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 86 saving montages\n",
            "Epoch: 87 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 87 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 11.7431 - MSE: 11.7431\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 11.7386 - MSE: 11.7386 - val_loss: 6479.2256 - val_MSE: 6479.2334\n",
            "Epoch: 87 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 87 saving montages\n",
            "Epoch: 88 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 88 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 10.0230 - MSE: 10.0230\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 9.9998 - MSE: 9.9998 - val_loss: 6835.6030 - val_MSE: 6835.6079\n",
            "Epoch: 88 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 88 saving montages\n",
            "Epoch: 89 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 89 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 16.5147 - MSE: 16.5147\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 16.4999 - MSE: 16.4999 - val_loss: 6147.9111 - val_MSE: 6147.9082\n",
            "Epoch: 89 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 89 saving montages\n",
            "Epoch: 90 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 90 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 10.2451 - MSE: 10.2450\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 10.2451 - MSE: 10.2450 - val_loss: 6699.3999 - val_MSE: 6699.4072\n",
            "Epoch: 90 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 90 saving montages\n",
            "Epoch: 91 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 91 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 8.9639 - MSE: 8.9639\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 8.9639 - MSE: 8.9639 - val_loss: 6780.6851 - val_MSE: 6780.6836\n",
            "Epoch: 91 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 91 saving montages\n",
            "Epoch: 92 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 92 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 8.9810 - MSE: 8.9809\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 8.9780 - MSE: 8.9780 - val_loss: 7621.2437 - val_MSE: 7621.2310\n",
            "Epoch: 92 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 92 saving montages\n",
            "Epoch: 93 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 93 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 14.8719 - MSE: 14.8719\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 14.8719 - MSE: 14.8719 - val_loss: 7853.0610 - val_MSE: 7853.0596\n",
            "Epoch: 93 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 93 saving montages\n",
            "Epoch: 94 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 94 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 13.5257 - MSE: 13.5257\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 13.5257 - MSE: 13.5257 - val_loss: 7650.3130 - val_MSE: 7650.3013\n",
            "Epoch: 94 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 94 saving montages\n",
            "Epoch: 95 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 95 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 7.5610 - MSE: 7.5610\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 7.5471 - MSE: 7.5471 - val_loss: 7667.8584 - val_MSE: 7667.8589\n",
            "Epoch: 95 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 95 saving montages\n",
            "Epoch: 96 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 96 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 14.2793 - MSE: 14.2793\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 14.2730 - MSE: 14.2730 - val_loss: 7643.0186 - val_MSE: 7643.0156\n",
            "Epoch: 96 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 96 saving montages\n",
            "Epoch: 97 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 97 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 11.5078 - MSE: 11.5078\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 11.5078 - MSE: 11.5078 - val_loss: 7919.8525 - val_MSE: 7919.8516\n",
            "Epoch: 97 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 97 saving montages\n",
            "Epoch: 98 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 98 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 15.1326 - MSE: 15.1326\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 15.1206 - MSE: 15.1206 - val_loss: 7387.9521 - val_MSE: 7387.9541\n",
            "Epoch: 98 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 98 saving montages\n",
            "Epoch: 99 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 99 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 12.8636 - MSE: 12.8636\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 40ms/step - loss: 12.8644 - MSE: 12.8644 - val_loss: 6940.7358 - val_MSE: 6940.7373\n",
            "Epoch: 99 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 99 saving montages\n",
            "Epoch: 100 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 100 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 11.1022 - MSE: 11.1022\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 11.0865 - MSE: 11.0865 - val_loss: 8449.6807 - val_MSE: 8449.6943\n",
            "Epoch: 100 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 100 saving montages\n",
            "Epoch: 101 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 101 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 10.8203 - MSE: 10.8203\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 10.8020 - MSE: 10.8020 - val_loss: 8441.4648 - val_MSE: 8441.4717\n",
            "Epoch: 101 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 101 saving montages\n",
            "Epoch: 102 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 102 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 13.8810 - MSE: 13.8810\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 13.8519 - MSE: 13.8519 - val_loss: 8598.4580 - val_MSE: 8598.4600\n",
            "Epoch: 102 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 102 saving montages\n",
            "Epoch: 103 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 103 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 13.3513 - MSE: 13.3513\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 13.3383 - MSE: 13.3383 - val_loss: 10501.4482 - val_MSE: 10501.4551\n",
            "Epoch: 103 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 103 saving montages\n",
            "Epoch: 104 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 104 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 45.3897 - MSE: 45.3898\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 45.3897 - MSE: 45.3898 - val_loss: 10399.2578 - val_MSE: 10399.2402\n",
            "Epoch: 104 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 104 saving montages\n",
            "Epoch: 105 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 105 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 24.0007 - MSE: 24.0007\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 23.9952 - MSE: 23.9952 - val_loss: 10047.4814 - val_MSE: 10047.4854\n",
            "Epoch: 105 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 105 saving montages\n",
            "Epoch: 106 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 106 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 19.7347 - MSE: 19.7347\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 19.6977 - MSE: 19.6977 - val_loss: 10943.4531 - val_MSE: 10943.4639\n",
            "Epoch: 106 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 106 saving montages\n",
            "Epoch: 107 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 107 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 14.6501 - MSE: 14.6501\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 14.6459 - MSE: 14.6459 - val_loss: 11493.3320 - val_MSE: 11493.3320\n",
            "Epoch: 107 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 107 saving montages\n",
            "Epoch: 108 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 108 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 22.0832 - MSE: 22.0832\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 22.0493 - MSE: 22.0493 - val_loss: 12548.4893 - val_MSE: 12548.4902\n",
            "Epoch: 108 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 108 saving montages\n",
            "Epoch: 109 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 109 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 23.3295 - MSE: 23.3295\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 23.3074 - MSE: 23.3073 - val_loss: 10604.2217 - val_MSE: 10604.2197\n",
            "Epoch: 109 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 109 saving montages\n",
            "Epoch: 110 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 110 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 30.4261 - MSE: 30.4261\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 30.3795 - MSE: 30.3795 - val_loss: 10272.6504 - val_MSE: 10272.6367\n",
            "Epoch: 110 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 110 saving montages\n",
            "Epoch: 111 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 111 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 24.7383 - MSE: 24.7383\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 24.7169 - MSE: 24.7168 - val_loss: 10875.0762 - val_MSE: 10875.0615\n",
            "Epoch: 111 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 111 saving montages\n",
            "Epoch: 112 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 112 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 19.7216 - MSE: 19.7216\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 19.7100 - MSE: 19.7100 - val_loss: 11741.4951 - val_MSE: 11741.5098\n",
            "Epoch: 112 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 112 saving montages\n",
            "Epoch: 113 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 113 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 14.7156 - MSE: 14.7156\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 14.7686 - MSE: 14.7686 - val_loss: 10248.3770 - val_MSE: 10248.3594\n",
            "Epoch: 113 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 113 saving montages\n",
            "Epoch: 114 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 114 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 33.2598 - MSE: 33.2598\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 33.2268 - MSE: 33.2268 - val_loss: 11786.9199 - val_MSE: 11786.9043\n",
            "Epoch: 114 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 114 saving montages\n",
            "Epoch: 115 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 115 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 18.9226 - MSE: 18.9226\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 18.9127 - MSE: 18.9127 - val_loss: 9297.1396 - val_MSE: 9297.1406\n",
            "Epoch: 115 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 115 saving montages\n",
            "Epoch: 116 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 116 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 20.8853 - MSE: 20.8853\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 20.8703 - MSE: 20.8703 - val_loss: 10740.2939 - val_MSE: 10740.2930\n",
            "Epoch: 116 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 116 saving montages\n",
            "Epoch: 117 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 117 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 37.7519 - MSE: 37.7519\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 38.1868 - MSE: 38.1869 - val_loss: 11723.5625 - val_MSE: 11723.5684\n",
            "Epoch: 117 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 117 saving montages\n",
            "Epoch: 118 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 118 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 16.5510 - MSE: 16.5510\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 16.5495 - MSE: 16.5495 - val_loss: 12100.4561 - val_MSE: 12100.4512\n",
            "Epoch: 118 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 118 saving montages\n",
            "Epoch: 119 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 119 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 29.6872 - MSE: 29.6872\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 29.6872 - MSE: 29.6872 - val_loss: 12776.4248 - val_MSE: 12776.4365\n",
            "Epoch: 119 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 119 saving montages\n",
            "Epoch: 120 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 120 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 14.4477 - MSE: 14.4477\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 14.4342 - MSE: 14.4342 - val_loss: 13817.0898 - val_MSE: 13817.0869\n",
            "Epoch: 120 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 120 saving montages\n",
            "Epoch: 121 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 121 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 30.5488 - MSE: 30.5488\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 30.5479 - MSE: 30.5479 - val_loss: 13953.7324 - val_MSE: 13953.7314\n",
            "Epoch: 121 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 121 saving montages\n",
            "Epoch: 122 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 122 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 25.2590 - MSE: 25.2590\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 25.3028 - MSE: 25.3028 - val_loss: 12490.2588 - val_MSE: 12490.2490\n",
            "Epoch: 122 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 122 saving montages\n",
            "Epoch: 123 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 123 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 23.8435 - MSE: 23.8435\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 23.8343 - MSE: 23.8343 - val_loss: 13101.7021 - val_MSE: 13101.7168\n",
            "Epoch: 123 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 123 saving montages\n",
            "Epoch: 124 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 124 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 37.2254 - MSE: 37.2254\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 37.1889 - MSE: 37.1889 - val_loss: 12937.2451 - val_MSE: 12937.2578\n",
            "Epoch: 124 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 124 saving montages\n",
            "Epoch: 125 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 125 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 28.8042 - MSE: 28.8042\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 28.7806 - MSE: 28.7805 - val_loss: 14321.6934 - val_MSE: 14321.6904\n",
            "Epoch: 125 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 125 saving montages\n",
            "Epoch: 126 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 126 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 24.6002 - MSE: 24.6002\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 24.6237 - MSE: 24.6237 - val_loss: 14018.5811 - val_MSE: 14018.5977\n",
            "Epoch: 126 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 126 saving montages\n",
            "Epoch: 127 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 127 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 26.9634 - MSE: 26.9634\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 26.9879 - MSE: 26.9879 - val_loss: 20904.6484 - val_MSE: 20904.6406\n",
            "Epoch: 127 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 127 saving montages\n",
            "Epoch: 128 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 128 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 49.1474 - MSE: 49.1473\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 49.1111 - MSE: 49.1110 - val_loss: 21117.3652 - val_MSE: 21117.3398\n",
            "Epoch: 128 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 128 saving montages\n",
            "Epoch: 129 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 129 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 38.1241 - MSE: 38.1241\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 38.0840 - MSE: 38.0840 - val_loss: 23765.2969 - val_MSE: 23765.2969\n",
            "Epoch: 129 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 129 saving montages\n",
            "Epoch: 130 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 130 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 39.8580 - MSE: 39.8580\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 39.9960 - MSE: 39.9960 - val_loss: 24993.4746 - val_MSE: 24993.4375\n",
            "Epoch: 130 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 130 saving montages\n",
            "Epoch: 131 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 131 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 81.1604 - MSE: 81.1604\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 81.1205 - MSE: 81.1205 - val_loss: 22485.4023 - val_MSE: 22485.3965\n",
            "Epoch: 131 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 131 saving montages\n",
            "Epoch: 132 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 132 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 35.7905 - MSE: 35.7905\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 39ms/step - loss: 35.7757 - MSE: 35.7757 - val_loss: 19377.9082 - val_MSE: 19377.9102\n",
            "Epoch: 132 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 132 saving montages\n",
            "Epoch: 133 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 133 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 59.4194 - MSE: 59.4194\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 59.3666 - MSE: 59.3666 - val_loss: 21474.8438 - val_MSE: 21474.8418\n",
            "Epoch: 133 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 133 saving montages\n",
            "Epoch: 134 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 134 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 31.3902 - MSE: 31.3901\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 31.3689 - MSE: 31.3689 - val_loss: 22470.8535 - val_MSE: 22470.8418\n",
            "Epoch: 134 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 134 saving montages\n",
            "Epoch: 135 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 135 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 43.7786 - MSE: 43.7785\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 43.7827 - MSE: 43.7827 - val_loss: 18468.3223 - val_MSE: 18468.3027\n",
            "Epoch: 135 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 135 saving montages\n",
            "Epoch: 136 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 136 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 59.0589 - MSE: 59.0589\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 59.0198 - MSE: 59.0198 - val_loss: 19511.0137 - val_MSE: 19511.0254\n",
            "Epoch: 136 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 136 saving montages\n",
            "Epoch: 137 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 137 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 29.1664 - MSE: 29.1664\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 29.1069 - MSE: 29.1069 - val_loss: 19680.4551 - val_MSE: 19680.4531\n",
            "Epoch: 137 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 137 saving montages\n",
            "Epoch: 138 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 138 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 26.8874 - MSE: 26.8874\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 26.8874 - MSE: 26.8874 - val_loss: 17452.4980 - val_MSE: 17452.4824\n",
            "Epoch: 138 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 138 saving montages\n",
            "Epoch: 139 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 139 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 33.6964 - MSE: 33.6964\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 33.6964 - MSE: 33.6964 - val_loss: 19397.7227 - val_MSE: 19397.6777\n",
            "Epoch: 139 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 139 saving montages\n",
            "Epoch: 140 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 140 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 58.5096 - MSE: 58.5096\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 58.5096 - MSE: 58.5096 - val_loss: 17209.5020 - val_MSE: 17209.4727\n",
            "Epoch: 140 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 140 saving montages\n",
            "Epoch: 141 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 141 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 31.9870 - MSE: 31.9870\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 31.9289 - MSE: 31.9289 - val_loss: 15635.8350 - val_MSE: 15635.7939\n",
            "Epoch: 141 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 141 saving montages\n",
            "Epoch: 142 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 142 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 29.3097 - MSE: 29.3097\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 29.2826 - MSE: 29.2826 - val_loss: 16423.4609 - val_MSE: 16423.4785\n",
            "Epoch: 142 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 142 saving montages\n",
            "Epoch: 143 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 143 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 47.5960 - MSE: 47.5960\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 47.4855 - MSE: 47.4856 - val_loss: 16703.1641 - val_MSE: 16703.1523\n",
            "Epoch: 143 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 143 saving montages\n",
            "Epoch: 144 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 144 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 23.8136 - MSE: 23.8136\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 23.8087 - MSE: 23.8087 - val_loss: 18556.2070 - val_MSE: 18556.2305\n",
            "Epoch: 144 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 144 saving montages\n",
            "Epoch: 145 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 145 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 73.9746 - MSE: 73.9746\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 73.9724 - MSE: 73.9724 - val_loss: 19718.3613 - val_MSE: 19718.3613\n",
            "Epoch: 145 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 145 saving montages\n",
            "Epoch: 146 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 146 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 29.0008 - MSE: 29.0008\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 29.0008 - MSE: 29.0008 - val_loss: 20181.8438 - val_MSE: 20181.8555\n",
            "Epoch: 146 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 146 saving montages\n",
            "Epoch: 147 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 147 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 24.2718 - MSE: 24.2718\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 24.2594 - MSE: 24.2594 - val_loss: 19383.0391 - val_MSE: 19383.0371\n",
            "Epoch: 147 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 147 saving montages\n",
            "Epoch: 148 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 148 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 53.4609 - MSE: 53.4609\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 53.3866 - MSE: 53.3866 - val_loss: 20249.8613 - val_MSE: 20249.8555\n",
            "Epoch: 148 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 148 saving montages\n",
            "Epoch: 149 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 149 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 31.2114 - MSE: 31.2114\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 31.2151 - MSE: 31.2151 - val_loss: 19112.1758 - val_MSE: 19112.1562\n",
            "Epoch: 149 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 149 saving montages\n",
            "Epoch: 150 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 150 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 27.0951 - MSE: 27.0952\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 27.0328 - MSE: 27.0328 - val_loss: 19342.2812 - val_MSE: 19342.2676\n",
            "Epoch: 150 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 150 saving montages\n",
            "Epoch: 151 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 151 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 27.8821 - MSE: 27.8821\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 27.8325 - MSE: 27.8325 - val_loss: 18683.2031 - val_MSE: 18683.1797\n",
            "Epoch: 151 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 151 saving montages\n",
            "Epoch: 152 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 152 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 27.8971 - MSE: 27.8971\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 27.8671 - MSE: 27.8671 - val_loss: 19199.3789 - val_MSE: 19199.3691\n",
            "Epoch: 152 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 152 saving montages\n",
            "Epoch: 153 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 153 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 36.4339 - MSE: 36.4338\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 36.4286 - MSE: 36.4286 - val_loss: 19215.3555 - val_MSE: 19215.4043\n",
            "Epoch: 153 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 153 saving montages\n",
            "Epoch: 154 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 154 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 27.7334 - MSE: 27.7334\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 27.7169 - MSE: 27.7168 - val_loss: 19961.9121 - val_MSE: 19961.8965\n",
            "Epoch: 154 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 154 saving montages\n",
            "Epoch: 155 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 155 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 39.0585 - MSE: 39.0585\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 44ms/step - loss: 39.0585 - MSE: 39.0585 - val_loss: 18749.1289 - val_MSE: 18749.1465\n",
            "Epoch: 155 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 155 saving montages\n",
            "Epoch: 156 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 156 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 25.2759 - MSE: 25.2759\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 25.2521 - MSE: 25.2521 - val_loss: 18609.0586 - val_MSE: 18609.0918\n",
            "Epoch: 156 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 156 saving montages\n",
            "Epoch: 157 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 157 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 21.5277 - MSE: 21.5277\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 21.5110 - MSE: 21.5110 - val_loss: 17841.5469 - val_MSE: 17841.5488\n",
            "Epoch: 157 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 157 saving montages\n",
            "Epoch: 158 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 158 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 37.2333 - MSE: 37.2333\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 37.2627 - MSE: 37.2627 - val_loss: 18147.1699 - val_MSE: 18147.1816\n",
            "Epoch: 158 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 158 saving montages\n",
            "Epoch: 159 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 159 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 21.6080 - MSE: 21.6080\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 21.7297 - MSE: 21.7297 - val_loss: 17658.9629 - val_MSE: 17658.9043\n",
            "Epoch: 159 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 159 saving montages\n",
            "Epoch: 160 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 160 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 26.5528 - MSE: 26.5528\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 26.7435 - MSE: 26.7435 - val_loss: 17558.9766 - val_MSE: 17558.9727\n",
            "Epoch: 160 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 160 saving montages\n",
            "Epoch: 161 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 161 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 33.0645 - MSE: 33.0645\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 32.9941 - MSE: 32.9940 - val_loss: 17110.3086 - val_MSE: 17110.2793\n",
            "Epoch: 161 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 161 saving montages\n",
            "Epoch: 162 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 162 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 16.0258 - MSE: 16.0258\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 39s 38ms/step - loss: 16.0258 - MSE: 16.0258 - val_loss: 16148.1885 - val_MSE: 16148.1709\n",
            "Epoch: 162 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 162 saving montages\n",
            "Epoch: 163 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 163 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 29.1104 - MSE: 29.1104\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 29.0624 - MSE: 29.0624 - val_loss: 16307.1875 - val_MSE: 16307.2119\n",
            "Epoch: 163 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 163 saving montages\n",
            "Epoch: 164 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 164 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 24.9188 - MSE: 24.9187\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 24.8942 - MSE: 24.8942 - val_loss: 15925.1904 - val_MSE: 15925.1973\n",
            "Epoch: 164 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 164 saving montages\n",
            "Epoch: 165 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 165 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 32.8184 - MSE: 32.8184\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 32.7456 - MSE: 32.7456 - val_loss: 17095.1230 - val_MSE: 17095.1113\n",
            "Epoch: 165 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 165 saving montages\n",
            "Epoch: 166 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 166 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 27.4547 - MSE: 27.4547\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 27.4573 - MSE: 27.4573 - val_loss: 17741.1855 - val_MSE: 17741.2031\n",
            "Epoch: 166 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 166 saving montages\n",
            "Epoch: 167 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 167 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 22.8349 - MSE: 22.8349\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 22.8298 - MSE: 22.8299 - val_loss: 17765.9961 - val_MSE: 17765.9668\n",
            "Epoch: 167 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 167 saving montages\n",
            "Epoch: 168 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 168 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 22.8006 - MSE: 22.8006\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 22.8204 - MSE: 22.8205 - val_loss: 19683.7930 - val_MSE: 19683.7754\n",
            "Epoch: 168 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 168 saving montages\n",
            "Epoch: 169 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 169 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 40.9852 - MSE: 40.9852\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 39s 38ms/step - loss: 41.0121 - MSE: 41.0121 - val_loss: 18231.3008 - val_MSE: 18231.2988\n",
            "Epoch: 169 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 169 saving montages\n",
            "Epoch: 170 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 170 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 23.4527 - MSE: 23.4527\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 23.4165 - MSE: 23.4165 - val_loss: 16097.3496 - val_MSE: 16097.3467\n",
            "Epoch: 170 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 170 saving montages\n",
            "Epoch: 171 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 171 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 17.3327 - MSE: 17.3327\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 17.3109 - MSE: 17.3109 - val_loss: 16605.6738 - val_MSE: 16605.6504\n",
            "Epoch: 171 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 171 saving montages\n",
            "Epoch: 172 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 172 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 37.2297 - MSE: 37.2296\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 37.3940 - MSE: 37.3940 - val_loss: 17306.2617 - val_MSE: 17306.2402\n",
            "Epoch: 172 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 172 saving montages\n",
            "Epoch: 173 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 173 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 31.8570 - MSE: 31.8571\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 31.8570 - MSE: 31.8571 - val_loss: 17901.9512 - val_MSE: 17901.9121\n",
            "Epoch: 173 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 173 saving montages\n",
            "Epoch: 174 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 174 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 25.6479 - MSE: 25.6479\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 25.6371 - MSE: 25.6372 - val_loss: 15366.3633 - val_MSE: 15366.3428\n",
            "Epoch: 174 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 174 saving montages\n",
            "Epoch: 175 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 175 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 34.4600 - MSE: 34.4600\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 34.4600 - MSE: 34.4600 - val_loss: 17198.8613 - val_MSE: 17198.8379\n",
            "Epoch: 175 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 175 saving montages\n",
            "Epoch: 176 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 176 training\n",
            " 996/1000 [============================>.] - ETA: 0s - loss: 24.7437 - MSE: 24.7437\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 24.6823 - MSE: 24.6824 - val_loss: 17418.8164 - val_MSE: 17418.8301\n",
            "Epoch: 176 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 176 saving montages\n",
            "Epoch: 177 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 177 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 38.3900 - MSE: 38.3900\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 39.6050 - MSE: 39.6050 - val_loss: 20847.6230 - val_MSE: 20847.5840\n",
            "Epoch: 177 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 177 saving montages\n",
            "Epoch: 178 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 178 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 34.4162 - MSE: 34.4162\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 34.3852 - MSE: 34.3852 - val_loss: 20855.4629 - val_MSE: 20855.5176\n",
            "Epoch: 178 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 178 saving montages\n",
            "Epoch: 179 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 179 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 86.2460 - MSE: 86.2460\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 40ms/step - loss: 86.5186 - MSE: 86.5186 - val_loss: 23598.9844 - val_MSE: 23599.0312\n",
            "Epoch: 179 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 179 saving montages\n",
            "Epoch: 180 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 180 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 18.4601 - MSE: 18.4601\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 18.5059 - MSE: 18.5059 - val_loss: 24254.7617 - val_MSE: 24254.7559\n",
            "Epoch: 180 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 180 saving montages\n",
            "Epoch: 181 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 181 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 25.0215 - MSE: 25.0215\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 25.0215 - MSE: 25.0215 - val_loss: 23113.0996 - val_MSE: 23113.1211\n",
            "Epoch: 181 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 181 saving montages\n",
            "Epoch: 182 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 182 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 36.6550 - MSE: 36.6549\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 36.6256 - MSE: 36.6256 - val_loss: 20986.3594 - val_MSE: 20986.3809\n",
            "Epoch: 182 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 182 saving montages\n",
            "Epoch: 183 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 183 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 19.4914 - MSE: 19.4914\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 38s 38ms/step - loss: 19.4604 - MSE: 19.4604 - val_loss: 21386.9141 - val_MSE: 21386.8828\n",
            "Epoch: 183 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 183 saving montages\n",
            "Epoch: 184 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 184 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 51.3226 - MSE: 51.3226\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 51.2775 - MSE: 51.2775 - val_loss: 23024.4824 - val_MSE: 23024.4395\n",
            "Epoch: 184 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 184 saving montages\n",
            "Epoch: 185 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 185 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 25.2765 - MSE: 25.2764\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 25.2765 - MSE: 25.2764 - val_loss: 24209.3652 - val_MSE: 24209.3789\n",
            "Epoch: 185 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 185 saving montages\n",
            "Epoch: 186 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 186 training\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 28.2799 - MSE: 28.2799\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 28.2799 - MSE: 28.2799 - val_loss: 22992.6680 - val_MSE: 22992.6406\n",
            "Epoch: 186 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 186 saving montages\n",
            "Epoch: 187 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 187 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 40.0098 - MSE: 40.0097\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 39.9287 - MSE: 39.9287 - val_loss: 21985.8105 - val_MSE: 21985.7891\n",
            "Epoch: 187 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 187 saving montages\n",
            "Epoch: 188 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 188 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 39.6870 - MSE: 39.6870\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 39.5916 - MSE: 39.5916 - val_loss: 22216.4668 - val_MSE: 22216.4355\n",
            "Epoch: 188 2nd predicting\n",
            "5/5 [==============================] - 0s 9ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 188 saving montages\n",
            "Epoch: 189 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 189 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 34.6560 - MSE: 34.6560\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 34.6290 - MSE: 34.6290 - val_loss: 22336.9316 - val_MSE: 22336.9434\n",
            "Epoch: 189 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 189 saving montages\n",
            "Epoch: 190 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 190 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 44.0734 - MSE: 44.0734\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 43.9978 - MSE: 43.9978 - val_loss: 23333.1836 - val_MSE: 23333.2070\n",
            "Epoch: 190 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 190 saving montages\n",
            "Epoch: 191 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 191 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 32.6763 - MSE: 32.6764\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 32.6495 - MSE: 32.6496 - val_loss: 24246.7812 - val_MSE: 24246.7676\n",
            "Epoch: 191 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 191 saving montages\n",
            "Epoch: 192 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 192 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 48.7872 - MSE: 48.7873\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 48.7157 - MSE: 48.7157 - val_loss: 23945.6074 - val_MSE: 23945.5957\n",
            "Epoch: 192 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 192 saving montages\n",
            "Epoch: 193 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 193 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 51.0059 - MSE: 51.0059\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 50.9520 - MSE: 50.9520 - val_loss: 23150.6543 - val_MSE: 23150.6738\n",
            "Epoch: 193 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 193 saving montages\n",
            "Epoch: 194 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 194 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 21.9004 - MSE: 21.9005\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 21.8826 - MSE: 21.8826 - val_loss: 21937.3086 - val_MSE: 21937.2910\n",
            "Epoch: 194 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 194 saving montages\n",
            "Epoch: 195 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 195 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 24.7990 - MSE: 24.7990\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 24.7752 - MSE: 24.7752 - val_loss: 19462.8574 - val_MSE: 19462.8613\n",
            "Epoch: 195 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 195 saving montages\n",
            "Epoch: 196 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 196 training\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 36.2119 - MSE: 36.2119\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 43s 42ms/step - loss: 36.1875 - MSE: 36.1875 - val_loss: 20754.0703 - val_MSE: 20754.0820\n",
            "Epoch: 196 2nd predicting\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 196 saving montages\n",
            "Epoch: 197 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 197 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 24.7456 - MSE: 24.7456\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 24.7559 - MSE: 24.7559 - val_loss: 21117.5332 - val_MSE: 21117.5195\n",
            "Epoch: 197 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 197 saving montages\n",
            "Epoch: 198 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 198 training\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 33.7923 - MSE: 33.7923\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 37s 37ms/step - loss: 33.8095 - MSE: 33.8095 - val_loss: 22657.8418 - val_MSE: 22657.8691\n",
            "Epoch: 198 2nd predicting\n",
            "5/5 [==============================] - 0s 9ms/step\n",
            "5/5 [==============================] - 0s 6ms/step\n",
            "Epoch: 198 saving montages\n",
            "Epoch: 199 1st predicting\n",
            "1000/1000 [==============================] - 4s 4ms/step\n",
            "Epoch: 199 training\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 44.2440 - MSE: 44.2440\n",
            "Epoch 1: saving model to model.hdf5\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 44.2424 - MSE: 44.2424 - val_loss: 22450.6016 - val_MSE: 22450.6191\n",
            "Epoch: 199 2nd predicting\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "Epoch: 199 saving montages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewvPAiHtwmzm",
        "outputId": "8347c106-f56e-4fbf-f274-cd511dd222d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network Loaded\n",
            "Predicting test data\n",
            "2686/2686 [==============================] - 15s 5ms/step\n",
            "tf.Tensor(0.8729205, shape=(), dtype=float32)\n",
            "tf.Tensor(4.618717, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "#Predict the validation data and print the SSIM and PSNR\n",
        "print('Predicting validation data')\n",
        "predictions = model.predict(valid, batch_size=2, verbose=1)\n",
        "SSIM = tf.image.ssim(predictions[:,:,:,0],label,max_val=255)\n",
        "PSNR = tf.image.psnr(predictions[:,:,:,0],label,max_val=255)\n",
        "print(SSIM)\n",
        "print(PSNR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make prediction for test data. Test data are sinogram image stacks instead of single sinograms.\n",
        "test= (np.load('test.npy',allow_pickle=True).astype('float32'))*255\n",
        "itr = 1\n",
        "for tilt in test:\n",
        "  predictions = model.predict(tilt, batch_size=2, verbose=1)\n",
        "  predictions[predictions<0] = 0\n",
        "  predictions[predictions>255] = 255\n",
        "  io.imsave('output/test_pred/'+str(itr)+'.tif', predictions.squeeze()/255  )\n",
        "  itr = itr+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s78Fl3VgRXy9",
        "outputId": "347d8257-ab78-4315-f32a-9ced3a10698f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128/128 [==============================] - 1s 6ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}